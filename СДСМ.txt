4.Делаем STP и RSTP
	
	Чтобы узнать какой коммутатор корневой введем команду:
	-sh spanning-tree vlan 3
	
	Сделаем нужный нам коммутатор корневым:
	-spanning-tree vlan 3 root primary
	
	Чтобы узнать режим работы коммутатора, введем:
	-sh spanning-tree summary
	
	Включим RSTP вместо STP. Для этого введем на всех коммутаторах:
	-spanning-tree mode rapid-pvst
	
	
5.ACL и NAT

ACL
Когда пакет проверяется, то все правила перебираются сверху вниз по порядку. Т.е. сначала проверяется не удовлетворяеn ли пакет первому правилу, потом второму.
Как только дошли до правила, под которое подподает пакет - проверка прекращается независимо от того какие правила будут дальше. Поэтому порядок имеет значение.

Входящий трафик — этот тот, который приходит на интерфейс извне.
Исходящий — тот, который отправляется с интерфейса вовне.

Стандартный список доступа проверяет только адрес отправителя. 
Расширенный- адрес отправителя, адрес получателя, а также порт.

Ограничение трафика на интерефейсе: применить правило можно на
входящем интерефейсе - в этом случае трафик не попадает за интерефейс 
исходящем интерфейсе - тогда он не выйдет с интерефейса

Возвращаемся к нашей схеме. Для начала ограничим доступ на WEB сервер по протоколу HTTP это порт 80.
Разрешить доступ всем по порту TCP 80 (протокол HTTP). Для того устройства, с которого будет производиться управление (у нас же есть админ) нужно открыть telnet и ftp, но ему мы дадим полный доступ. Всем остальным отбой

deny ip any any — то оно всегда будет срабатывать и трафик не будет ходить вообще. 
Any — это специальное слово, которое означает адрес сети и обратную маску 0.0.0.0 0.0.0.0 и означает, что под правило подпадают абсолютно все узлы из любых сетей.
host — оно означает маску 255.255.255.255 — то есть именно один единственный указанный адрес.
 
Заходим на msk-arbat-gw1
Поскольку мы собираемся фильтровать трафик по адресу назначения, нам понадобится расширенный список доступа.
	ip access-list extended Servers-out
	remark WEB
	permit tcp any host 172.16.0.2 eq 80
	
Разрешаем (permit) TCP-трафик от любого узла (any) на хост (host — именно один адрес) 172.16.0.2, адресованный на 80-й порт.
Пробуем повесить этот список доступа на интерфейс gig0/1.3:

	int gig0/1.3
	ip access-group Servers-out out
	
Но  теперь пинга до него не будет. Дело в том, что после всех правил в цисковских ACL в конце дописывается неявное deny ip any any (implicit deny). 
Что для нас это означает? Любой пакет, выходящий с интерфейса и не отвечающий ни одному правилу из ACL, подпадает под implicit deny и отбрасывается.
То есть хоть пинг, хоть фтп, хоть что угодно здесь уже не пройдёт.

Разрешим вход админу из компа Other1 с адресом 172.16.6.66 на наш WEB сервер
	ip access-list extended Servers-out
	permit tcp host 172.16.6.66 host 172.16.0.2 range 20 ftp
	permit tcp host 172.16.6.66 host 172.16.0.2 eq telnet
	
	
Теперь настроим доступ на файловый сервер для всех, кто имеет адрес из сети 172.16.0.0/16
	ip access-list extended Servers-out
	permit tcp 172.16.0.0 0.0.255.255 host 172.16.0.3 eq 445
	permit tcp any host 172.16.0.3 range 20 21

Теперь с общими папками. В большинстве современных систем уже используется для этого протокол SMB, которому нужен порт TCP 445.
Договорившись с нашим админом, настроим 445 порт (правда проверить в рамках РТ, конечно, не получится). Но кроме этого, нам понадобятся
порты для FTP — 20, 21, причём не только для внутренних хостов, но и для соединений из интернета.	
	

Настроим почтовый сервер 
	ip access-list extended Servers-out
	permit tcp any host 172.16.0.4 eq pop3
	permit tcp any host 172.16.0.4 eq smtp
	
	
	
	
И закончим все настройкой DNS сервера
	ip access-list extended Servers-out
	remark DNS
	permit udp 172.16.0.0 0.0.255.255 host 172.16.0.5 eq domain

Примеры
	ip access-list extended Servers-out
	permit tcp host 172.16.6.66 host 172.16.0.2 range 20 ftp
	
	ip access-list extended Management-out
	permit ip host 172.16.6.66 172.16.1.0 0.0.0.255
	
	ip access-list extended nat-inet
	permit ip host 172.16.6.66 any
	
NAT
Эта технология, которая преобразует серые ip адреса в белые, позволяя пользователям выходить в интернет.
NAT бывает:
	Статический: один внутренний адрес преобразуется в один внешний
		Настраивается следующей командой:
		ip nat inside source static 172.16.6.5 198.51.100.2
	
	Динамический: у нас есть пул белых адресов, каждый из которых присваивается локальному пользователю в рандомном порядке.
		Настраивается он так:
		Задаем пул (диапазон) публичных адресов, из которого будет выбираться адрес для натирования
		ip nat pool lol_pool 198.51.100.3 198.51.100.14 

		Задаём список доступа, который пропускает все пакеты с адресом источника 172.16.6.х, где х варьируется 0-255.
		access-list 100 permit ip 172.16.6.0 0.0.0.255 any

		И запускаем
		ip nat inside source list 100 pool lol_pool
		
	Перегруженный: один белый адрес присваивается группе локальных пользователей
		Настройка отличается совершенно незначительно: добавочным словом overload:
		access-list 101 permit 172.16.4.0 0.0.0.255
		ip nat inside source list 101 interface fa0/1 overload


		При этом, разумеется, сохраняется возможность настроить пул адресов:
		ip nat pool lol_pool 198.51.100.2 198.51.100.14 
		access-list 100 permit 172.16.6.0 0.0.0.255
		ip nat inside source list 100 pool lol_pool overload
		
Перенаправление портов
Это нужно чтобы "впустить" кого-то внутрь нашей сети, например, к WEB-серверу.

Вы можете указать, что все запросы, приходящие на конкретный белый адрес и конкретный порт маршрутизатора, должны быть перенаправлены на нужный порт нужного внутреннего адреса.
	ip nat inside source static tcp 172.16.0.2 80 198.51.100.2 80 extendable

Применение данной команды означает, что TCP-запрос, пришедший из интернета на адрес 198.51.100.2 по порту 80, будет перенаправлен на внутренний адрес 172.16.0.2 на тот же 80-й порт. Разумеется, вы можете пробрасывать и UDP и делать перенаправление с одного порта на другой. Это, например, может оказаться полезным, если у вас есть два компьютера, к которым нужен доступ по RDP извне. RDP использует порт 3389. Один и тот же порт вы не можете пробросить на разные хосты (при использовании одного внешнего адреса). Поэтому вы можете сделать так:
	ip nat inside source static tcp 172.16.6.61 3389 198.51.100.2 3389 
	ip nat inside source static tcp 172.16.6.66 3389 198.51.100.2 3398 

Тогда, чтобы попасть на компьютер 172.16.6.61 вы запускаете RDP-сессию на порт 198.51.100.2:3389, а на 172.16.6.66 — 198.51.100.2:3398. Маршрутизатор сам раскидает всё, куда надо.

Плюсы и минусы NAT:

Плюсы:
	экономия ip - адресов
	в какой-то степени файервол
	скрывает от посторонних глаз внутреннюю структуру вашей сети
	
Минусы:
	Некоторые протоколы не могут работать через NAT без костылей
	с одного адреса идёт много запросов на один сервер
	
Приступим к практике. 

Для начала создадим пул белых  ip-адресов:
	ip nat pool main_pool 198.51.100.2 198.51.100.14 netmask 255.255.255.240
	
Собираем ACL:
	ip access-list extended nat-inet

1) Хосты из сети ПТО
Имеют доступ только к профильным сайтам, например, Linkmeup.ru
	msk-arbat-gw1(config-ext-nacl)# permit tcp 172.16.3.0 0.0.0.255 host 192.0.2.2 eq 80
	
2) ФЭО
Даём разрешение только финансовому директору — это только один хост.
	msk-arbat-gw1(config-ext-nacl)# permit ip host 172.16.4.123 any

3) Other
Наши компьютеры с полным доступом
	msk-arbat-gw1(config-ext-nacl)# permit ip host 172.16.6.61 any
	msk-arbat-gw1(config-ext-nacl)# permit ip host 172.16.6.66 any

4) Филиалы в Санкт-Петербурге и Кемерово
Пусть адреса эникиев будут одинаковыми: 172.16.х.222
	msk-arbat-gw1(config-ext-nacl)# permit ip host 172.16.16.222 any
	msk-arbat-gw1(config-ext-nacl)# permit ip host 172.16.17.222 any
	msk-arbat-gw1(config-ext-nacl)# permit ip host 172.16.24.222 any
	
Запускаем:
	msk-arbat-gw1(config)# ip nat inside source list nat-inet pool main_pool overload
	
Но счастье не будет полным без настройки интерфейсов:
На внешнем интерфейсе нужно дать команду ip nat outside
На внутреннем: ip nat inside
	msk-arbat-gw1(config)# int gig0/1.101
	msk-arbat-gw1(config-subif)# ip nat inside 
	msk-arbat-gw1(config)# int gig0/1.102
	msk-arbat-gw1(config-subif)# ip nat inside 
	msk-arbat-gw1(config)# int gig0/1.103
	msk-arbat-gw1(config-subif)# ip nat inside 
	msk-arbat-gw1(config)# int gig0/1.104
	msk-arbat-gw1(config-subif)# ip nat inside 
	msk-arbat-gw1(config)# int gig0/2.6
	msk-arbat-gw1(config-subif)# ip nat outside 
	
Это позволит маршрутизатору понять откуда ждать пакеты, которые нужно будет обработать и куда их потом слать.

Ну а теперь сделаем проброс портов, чтобы мы могли подключться к нашим серверам извне. 
a) Веб-сервер
	msk-arbat-gw1(config)# ip nat inside source static tcp 172.16.0.2 80 198.51.100.2 80
И укажем тип порта, что бы маршрутизатор понимал куда слать запрос
	msk-arbat-gw1(config)# int gig0/1.3
	msk-arbat-gw1(config-subif)# ip nat inside

б) Файловый сервер
	msk-arbat-gw1(config)# ip nat inside source static tcp 172.16.0.3 20 198.51.100.3 20
	msk-arbat-gw1(config)# ip nat inside source static tcp 172.16.0.3 21 198.51.100.3 21
Вот для этого в ACL Servers-out мы открывали также и 20-21-й порты для всех

в) Почтовый сервер
	msk-arbat-gw1(config)# ip nat inside source static tcp 172.16.0.4 25 198.51.100.4 25
	msk-arbat-gw1(config)# ip nat inside source static tcp 172.16.0.4 110 198.51.100.4 110

г) Доступ по RDP к компьютерам админа и нашему
	msk-arbat-gw1(config)# ip nat inside source static tcp 172.16.6.61 3389 198.51.100.10 3389
	msk-arbat-gw1(config)# ip nat inside source static tcp 172.16.6.66 3389 198.51.100.10 3398


Динамическая маршрутизация

Смысл динамической маршрутизации в том, что бы не прописывать вручную все маршруты. За нас это делают сами маршрутизаторы. Они обмениваются таблицами маршрутизации, сами выстраивают топологию сети и, в случае обрывов, перенаправляют трафик в нужную сторону.

Все протоколы маршрутизации можно разделить на две большие группы: 
	внешние (EGP — Exterior Gateway Protocol)
	внутренние (IGP — Interior Gateway Protocol).   

В свою очередь, внутренние протоколы маршрутизации подразделяются на
	Distance-Vector (RIP, EIGRP) 
	Link State (OSPF, IS-IS)

Если на маршрутизаторах настроено несколько протоколов динамической маршрутизации, то предпочтение отдается протоколу с наименьшей административной дистанцией.

OSPF

OSPF — протокол динамической маршрутизации, основанный на технологии отслеживания состояния канала и использующий для нахождения кратчайшего пути алгоритм Дейкстры.

Для начала надо сказать, что для того, чтобы между маршрутизаторами завязалась дружба (отношения смежности) должны выполниться следующие условия:

	1) в OSPF должны быть настроены одинаковые Hello Interval на тех маршрутизаторах, что подключены друг к другу. По умолчанию это 10 секунд в Broadcast сетях, типа Ethernet. Это своего рода KeepAlive сообщения. То есть каждые 10 секунд каждый маршрутизатор отправляет Hello пакет своему соседу, чтобы сказать: “Хей, я жив”,
	2) Одинаковыми должны быть и Dead Interval на них. Обычно это 4 интервала Hello — 40 секунд. Если в течение этого времени от соседа не получено Hello, то он считается недоступным и начинается ПАНИКА процесс перестроения локальной базы данных и рассылка обновлений всем соседям,
	3) Интерфейсы, подключенные друг к другу, должны быть в одной подсети,
	4) OSPF позволяет снизить нагрузку на CPU маршрутизаторов, разделив Автономную Систему на зоны. Так вот номера зон тоже должны совпадать,
	5) У каждого маршрутизатора, участвующего в процессе OSPF есть свой уникальный индентификатор — Router ID. Если вы о нём не позаботитесь, то маршрутизатор выберет его автоматически на основе информации о подключенных интерфейсах (выбирается высший адрес из интерфейсов, активных на момент запуска процесса OSPF). Но опять же у хорошего инженера всё под контролем, поэтому обычно создаётся Loopback интерфейс, которому присваивается адрес с маской /32 и именно он назначается Router ID. Это бывает удобно при обслуживании и траблшутинге.
	6) Должен совпадать размер MTU
	
Как работает OSPF на примере 2 подключенных к друг другу маршрутизаторов - R1 и R2

1)Штиль. Состояние OSPF — DOWN

2) Поднимается ветер: маршрутизатор рассылает Hello-пакеты на мультикастный адрес 224.0.0.5 со всех интерфейсов, где запущен OSPF. TTL таких сообщений равен одному, поэтому их получат только маршрутизаторы, находящиеся в том же сегменте сети. R1 переходит в состояние INIT.

В пакеты вкладывается следующая информация:
Router ID
Hello Interval
Dead Interval
Neighbors
Subnet mask
Area ID
Router Priority
Адреса DR и BDR маршрутизаторов
Пароль аутентификации

Сообщение Hello от маршрутизатора R1 несёт в себе его Router ID и не содержит Neighbors, потому что у него их пока нет.
После получения этого мультикастного сообщения маршрутизатор R2 добавляет R1 в свою таблицу соседей (если совпали все необходимые параметры).
И отправляет на R1 уже юникастом новое сообщение Hello, где содержится Router ID этого маршрутизатора, а в списке Neigbors перечислены все его соседи. В числе прочих соседей в этом списке есть Router ID R1, то есть R2 уже считает его соседом.

3) Дружба. Когда R1 получает это сообщение Hello от R2, он пролистывает список соседей и находит в нём свой собственный Router ID, он добавляет R2 в свой список соседей.
Теперь R1 и R2 друг у друга во взаимных соседях — это означает, что между ними установлены отношения смежности и маршрутизатор R1 переходит в состояние TWO WAY.
Далее происходит выбор DR(Выделенный маршрутизатор) и BDR(Резервный выделенный маршрутизатор)

4) Затишье перед бурей. Далее все переходят в состояние EXSTART. Здесь все соседи решают между собой, кто босс. Им становится маршрутизатор с наибольшим Router ID — R2.

5) Когда выбран Батька, соседи переходят в состояние Exchange и обмениваются DBD-сообщениями (или DD) — Data Base Description, которые содержат описание LSDB (Link State Data Base), мол, я знаю про вот такие подсети.
Тут надо пояснить, что такое LSDB. Если перевести на русский дословно: база данных о состоянии линков. В изначальном состоянии маршрутизатор знает только о тех линках (интерфейсах), на которых запущен процесс OSPF. По ходу пьесы, каждый маршрутизатор собирает всю информацию о сети и составляет топологию. Именно она и будет являться LSDB, которая должна быть одинакова на всех членах зоны.
Первым отсылает свою DBD маршрутизатор, выбранный главным на данном интерфейсе — 2.2.2.2. Следом за ним то же делает и 1.1.1.1.

6) Получив сообщение, маршрутизаторы R1 и R2 отправляют подтверждение о приёме DBD (LSAck), а затем сравнивают новую информацию с той, что содержится у них в LSDB и, если есть отличия, посылают LSR (Link State Request) друг другу, тем самым переходя в новое состояние LOADING. В LSR они говорят — “Я про вот эту сеть ничего не знаю. Расскажи мне подробнее”.

7) R2, получив LSR от R1, высылает LSU (Link State Update), которые содержат в себе LSA (Link State Advertisement) c детальной информацией о нужных подсетях.
И вот, как только R1 получит последнюю порцию данных о всех подсетях и сформирует свою LSDB, он переходит в своё конечное состояние FULL STATE.
К тому моменту, как все маршрутизаторы зоны придут к состоянию Full State на всех на них должна быть полностью одинаковая LSDB — они же одну и ту же сеть изучали. То есть фактически это означает, что маршрутизатор знает всю вашу сеть, что, как и куда подключено.

8) Итак, сейчас у нас все маршрутизаторы знают всё о сети, но это знание не помогает в маршрутизации.
Следующим шагом OSPF, используя алгоритм Дейкстры (или его ещё называют SPF — Shortest Path First), вычисляет кратчайший маршрут до каждого маршрутизатора в зоне — он ведь знает всю топологию. В этом ему помогают метрики. Чем она ниже, тем маршрут лучше. Метрика — это стоимость движения по маршруту.

LSAck - подтверждение о приеме DBD
LSR - запрос на данные о подключениях (Link State Update)
LSU - 
LSA
LSDB




Мультикаст

Как известно, существуют следующие типы трафика:
	-Unicast — одноадресная рассылка — один отправитель, один получатель. (Пример: запрос HTTP-странички у WEB-сервера).
	-Broadcast — широковещательная рассылка — один отправитель, получатели — все устройства в широковещательном сегменте. (Пример: ARP-запрос).
	-Multicast — многоадресная рассылка — один отправитель, много получателей. (Пример: IPTV).
	-Anycast — одноадресная рассылка ближайшему узлу — один отправитель, вообще получателей много, но фактически данные отправляются только одному.
	
На мультикасте пересылаются UDP пакеты, так как трафик нужен "здесь и сейчас". 

В IPv4 был заложен блок адресов класса D: 224.0.0.0/4 (224.0.0.0-239.255.255.255). Адреса этого диапазона определяют мультикастовую группу. Один адрес — это одна группа, обычно она обозначается буквой «G».
То есть, говоря, что клиент подключен к группе 224.2.2.4, мы имеем ввиду, что он получает мультикастовый трафик с адресом назначения 224.2.2.4.

Вообще, чтобы доставить мультикаст от источника до получателя на данный момент существует много протоколов — IGMP/MLD, PIM, MSDP, MBGP, MOSPF, DVMRP.
Мы остановимся на двух из них, которые используются в настоящее время: PIM и IGMP.
С помощью IGMP конечные получатели-клиенты сообщают ближайшим маршрутизаторам о том, что хотят получать трафик. А PIM строит путь движения мультикастового трафика от источника до получателей через маршрутизаторы.



IGMP

IGMP — Internet Group Management Protocol — это сетевой протокол взаимодействия клиентов мультикастового трафика и ближайшего к ним маршрутизатора.

Если взять дамп трафика, то первый пакет, который мы увидим, будет именно от IGMP. Это сообщение протокола IGMP, которое отправил клиент, когда мы на нём нажали Play. Именно так он сообщает о том, что хочет получать трафик для группы 224.2.2.4.

Роль IGMP очень проста: если клиентов нет — передавать мультикастовый трафик в сегмент не надо. Если появился клиент, он уведомляет маршрутизаторы с помощью IGMP о том, что хочет получать трафик.

Маршрутизатор получает IGMP-Report и, понимая, что за данным интерфейсом теперь есть клиенты, заносит информацию в свои таблицы

Посмотреть эту информацию можно следующими командами:
	show ip igmp groups - юникастовая таблица маршрутизации
	show ip mroute 224.2.2.4 - мультикастовая таблица маршрутизации
	
Интерфейсы, в которые нужно передавать трафик, входят в список нисходящих интерфейсов — OIL — Outbound Interface List.

 Клиент начал получать трафик. Теперь маршрутизатор должен иногда проверять, что получатели до сих пор у него есть. Для этого он периодически отправляет во все свои нисходящие интерфейсы запрос IGMP Query.

Получив IGMP General Query, любой хост, который слушает любую группу, должен отправить IGMP Report, как он это делал при подключении. В Report, естественно, должен быть указан адрес интересующей его группы.

 Если в ответ на Query на маршрутизатор пришёл хотя бы один Report для группы, значит есть ещё клиенты, он продолжает вещать в тот интерфейс, откуда пришёл этот Report, трафик этой самой группы.
 
Если на 3 подряд Query не было с интерфейса ответа для какой-то группы, маршрутизатор удаляет этот интерфейс из своей таблицы мультикастовой маршрутизации для данной группы — перестаёт туда посылать трафик.

По своей инициативе клиент обычно посылает Report только при подключении, потом — просто отвечает на Query от маршрутизатора.

Так продолжается веками, пока клиент не захочет выйти из группы (например, выключит плеер/телевизор). В этом случае он отправляет IGMP Leave на адрес группы.

В ответ на IGMP Leave маршрутизатор высылает IGMP Query на адрес группы, для которой этот Leave пришёл в тот интерфейс, откуда он пришёл. Такой пакет называется Group Specific Query. На него отвечают только те клиенты, которые подключены к данной конкретной группе.

Если маршрутизатор получил ответный Report для группы, он продолжает вещать в интерфейс, если не получил — удаляет по истечении таймера.

Всего после получения Leave отправляется два Group Specific Query — один обязательный, второй контрольный.


Querier
А что происходит, если к коммутатору подключен не один, а несколько маршрутизаторов? сли ничего не сделать, мультикастовый трафик будет дублироваться — оба маршрутизатора ведь будут получать Report от клиентов. Во избежание этого существует механизм выбора Querier — опрашивателя. Тот кто победит, будет посылать Query, мониторить Report и реагировать на Leave, ну и, соответственно, он будет отправлять и трафик в сегмент. Проигравший же будет только слушать Report и держать руку на пульсе.

Выборы происходят довольно просто и интуитивно понятно.
Рассмотрим ситуацию с момента включения маршрутизаторов R1 и R2.
	1) Активировали IGMP на интерфейсах.
	2) Сначала по умолчанию каждый из них считает себя Querier.
	3) Каждый отправляет IGMP General Query в сеть. Главная цель — узнать, есть ли клиенты, а параллельно — заявить другим маршрутизаторам в сегменте, если они есть, о своём желании участвовать в выборах.
	4) General Query получают все устройства в сегменте, в том числе и другие IGMP-маршрутизаторы.
	5) Получив такое сообщение от соседа, каждый маршрутизатор оценивает, кто достойнее.
	6) Побеждает маршрутизатор с меньшим IP (указан в поле Source IP пакета IGMP Query). Он становится Querier, все другие — Non-Querier.
	7) Non-Querier запускает таймер, который обнуляется каждый раз, как приходит Query с меньшим IP-адресом. Если до истечения таймера (больше 100 секунд: 105-107) маршрутизатор не получит Query с меньшим адресом, он объявляет себя Querier и берёт на себя все соответствующие функции.
	8) Если Querier получает Query с меньшим адресом, он складывает с себя эти обязанности. Querier'ом становится другой маршрутизатор, у которого IP меньше.
	
Повторим ещё раз
	1. Первым делом маршрутизатор отправил свой IGMP General Query после включения IGMP на его интерфейсе, чтобы узнать, есть ли получатели и заявить о своём желании быть Querier. На тот момент никого не было в этой группе.
	2. Далее появился клиент, который захотел получать трафик группы 224.2.2.4 и он отправил свой IGMP Report. После этого пошёл трафик на него, но он отфильтрован из дампа.
	3. Потом маршрутизатор решил зачем-то проверить — а нет ли ещё клиентов и отправил IGMP General Query ещё раз, на который клиент вынужден ответить (4).
	5. Периодически (раз в минуту) маршрутизатор проверяет, что получатели по-прежнему есть, с помощью IGMP General Query, а узел подтверждает это с помощью IGMP Report.
	6. Потом он передумал и отказался от группы, отправив IGMP Leave.
	7. Маршрутизатор получил Leave и, желая убедиться, что больше никаких других получателей нет, посылает IGMP Group Specific Query… дважды. И по истечении таймера перестаёт передавать трафик сюда.
	8. Однако передавать IGMP Query в сеть он по-прежнему продолжает. Например, на тот случай, если вы плеер не отключали, а просто где-то со связью проблемы. Потом связь восстанавливается, но клиент-то Report не посылает сам по себе. А вот на Query отвечает. Таким образом поток может восстановиться без участия человека.

И ещё раз

IGMP — протокол, с помощью которого маршрутизатор узнаёт о наличии получателей мультикастового трафика и об их отключении.
IGMP Report — посылается клиентом при подключении и в ответ на IGMP Query. Означает, что клиент хочет получать трафик конкретной группы.
IGMP General Query — посылается маршрутизатором периодически, чтобы проверить какие группы сейчас нужны. В качестве адреса получателя указывается 224.0.0.1.
IGMP Group Sepcific Query — посылается маршрутизатором в ответ на сообщение Leave, чтобы узнать есть ли другие получатели в этой группе. В качестве адреса получателя указывается адрес мультикастовой группы.
IGMP Leave — посылается клиентом, когда тот хочет покинуть группу.
Querier — если в одном широковещательном сегменте несколько маршрутизаторов, который могут вещать, среди них выбирается один главный — Querier. Он и будет периодически рассылать Query и передавать трафик.






	
	
	

  	